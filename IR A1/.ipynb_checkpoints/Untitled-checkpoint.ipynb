{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3000b281-64df-462e-92a5-5da0a15e9713",
   "metadata": {},
   "source": [
    "Code adapted from: https://www.kaggle.com/uthamkanth/beginner-tf-idf-and-cosine-similarity-from-scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6635df4-ebc2-4837-8fd9-f7c2a423316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c770502-1225-4087-8fe3-c2dcdcafa862",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = \"Shipment of gold damaged in a fire. Gold.\"\n",
    "d2 = \"Delivery of silver arrived in a silver truck\"\n",
    "d3 = \"Shipment of gold arrived in a truck\"\n",
    "q = \"gold silver truck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0cbc961-e7b3-4ace-9384-a60f78d76060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Document  gold  damaged  Shipment  of  Gold.  fire.  a  in\n",
      "0  Term Frequency     1        1         1   1      1      1  1   1\n",
      "         Document  truck  silver  of  Delivery  a  arrived  in\n",
      "0  Term Frequency      1       2   1         1  1        1   1\n",
      "         Document  gold  truck  Shipment  of  a  arrived  in\n",
      "0  Term Frequency     1      1         1   1  1        1   1\n"
     ]
    }
   ],
   "source": [
    "def compute_tf(docs_list):\n",
    "    for doc in docs_list:\n",
    "        doc1_lst = doc.split(\" \")\n",
    "        wordDict_1= dict.fromkeys(set(doc1_lst), 0)\n",
    "\n",
    "        for token in doc1_lst:\n",
    "            wordDict_1[token] +=  1\n",
    "        df = pd.DataFrame([wordDict_1])\n",
    "        idx = 0\n",
    "        new_col = [\"Term Frequency\"]    \n",
    "        df.insert(loc=idx, column='Document', value=new_col)\n",
    "        print(df)\n",
    "        \n",
    "compute_tf([d1, d2, d3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7ba3cfe-8e9a-4cfe-b6f3-0fdb0496e69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Document   gold  damaged  Shipment     of  Gold.  fire.      a     in\n",
      "0  Normalized TF  0.125    0.125     0.125  0.125  0.125  0.125  0.125  0.125\n",
      "        Document  truck  silver     of  Delivery      a  arrived     in\n",
      "0  Normalized TF  0.125    0.25  0.125     0.125  0.125    0.125  0.125\n",
      "        Document      gold     truck  Shipment        of         a   arrived  \\\n",
      "0  Normalized TF  0.142857  0.142857  0.142857  0.142857  0.142857  0.142857   \n",
      "\n",
      "         in  \n",
      "0  0.142857  \n"
     ]
    }
   ],
   "source": [
    "def termFrequency(term, document):\n",
    "    normalizeDocument = document.lower().split()\n",
    "    return normalizeDocument.count(term.lower()) / float(len(normalizeDocument))\n",
    "\n",
    "def compute_normalizedtf(documents):\n",
    "    tf_doc = []\n",
    "    for txt in documents:\n",
    "        sentence = txt.split()\n",
    "        norm_tf= dict.fromkeys(set(sentence), 0)\n",
    "        for word in sentence:\n",
    "            norm_tf[word] = termFrequency(word, txt)\n",
    "        tf_doc.append(norm_tf)\n",
    "        df = pd.DataFrame([norm_tf])\n",
    "        idx = 0\n",
    "        new_col = [\"Normalized TF\"]    \n",
    "        df.insert(loc=idx, column='Document', value=new_col)\n",
    "        print(df)\n",
    "    return tf_doc\n",
    "\n",
    "tf_doc = compute_normalizedtf([d1, d2, d3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23d05818-ec0a-4cd2-9bad-80abc9e53373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Shipment': 1.4054651081081644,\n",
       " 'of': 1.0,\n",
       " 'gold': 1.4054651081081644,\n",
       " 'damaged': 2.09861228866811,\n",
       " 'in': 1.0,\n",
       " 'a': 1.0,\n",
       " 'fire.': 2.09861228866811,\n",
       " 'Gold.': 2.09861228866811,\n",
       " 'Delivery': 2.09861228866811,\n",
       " 'silver': 2.09861228866811,\n",
       " 'arrived': 1.4054651081081644,\n",
       " 'truck': 1.4054651081081644}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inverseDocumentFrequency(term, allDocuments):\n",
    "    numDocumentsWithThisTerm = 0\n",
    "    for doc in range (0, len(allDocuments)):\n",
    "        if term.lower() in allDocuments[doc].lower().split():\n",
    "            numDocumentsWithThisTerm = numDocumentsWithThisTerm + 1\n",
    " \n",
    "    if numDocumentsWithThisTerm > 0:\n",
    "        return 1.0 + math.log(float(len(allDocuments)) / numDocumentsWithThisTerm)\n",
    "    else:\n",
    "        return 1.0\n",
    "    \n",
    "def compute_idf(documents):\n",
    "    idf_dict = {}\n",
    "    for doc in documents:\n",
    "        sentence = doc.split()\n",
    "        for word in sentence:\n",
    "            idf_dict[word] = inverseDocumentFrequency(word, documents)\n",
    "    return idf_dict\n",
    "idf_dict = compute_idf([d1, d2, d3])\n",
    "\n",
    "compute_idf([d1, d2, d3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5e31747-263e-4195-9a8a-b08b446f00b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   doc      gold    silver     truck\n",
      "0    0  0.175683  0.000000  0.000000\n",
      "1    1  0.000000  0.524653  0.175683\n",
      "2    2  0.200781  0.000000  0.200781\n"
     ]
    }
   ],
   "source": [
    "# tf-idf score across all docs for the query string(\"life learning\")\n",
    "def compute_tfidf_with_alldocs(documents , query):\n",
    "    tf_idf = []\n",
    "    index = 0\n",
    "    query_tokens = query.split()\n",
    "    df = pd.DataFrame(columns=['doc'] + query_tokens)\n",
    "    for doc in documents:\n",
    "        df['doc'] = np.arange(0 , len(documents))\n",
    "        doc_num = tf_doc[index]\n",
    "        sentence = doc.split()\n",
    "        for word in sentence:\n",
    "            for text in query_tokens:\n",
    "                if(text == word):\n",
    "                    idx = sentence.index(word)\n",
    "                    tf_idf_score = doc_num[word] * idf_dict[word]\n",
    "                    tf_idf.append(tf_idf_score)\n",
    "                    df.iloc[index, df.columns.get_loc(word)] = tf_idf_score\n",
    "        index += 1\n",
    "    df.fillna(0 , axis=1, inplace=True)\n",
    "    return tf_idf , df\n",
    "            \n",
    "documents = [d1, d2, d3]\n",
    "tf_idf , df = compute_tfidf_with_alldocs(documents , q)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77a9e364-6041-40d9-afe6-ee660a002d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gold': 0.3333333333333333, 'silver': 0.3333333333333333, 'truck': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "def compute_query_tf(q):\n",
    "    query_norm_tf = {}\n",
    "    tokens = q.split()\n",
    "    for word in tokens:\n",
    "        query_norm_tf[word] = termFrequency(word , q)\n",
    "    return query_norm_tf\n",
    "query_norm_tf = compute_query_tf(q)\n",
    "print(query_norm_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c2f84c-96e3-42bf-815c-865594f0810b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-b1ad74235d92>:21: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "  from collections import Iterable\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(tfidf_dict_qry, df , query , doc_num):\n",
    "    dot_product = 0\n",
    "    qry_mod = 0\n",
    "    doc_mod = 0\n",
    "    tokens = query.split()\n",
    "   \n",
    "    for keyword in tokens:\n",
    "        dot_product += tfidf_dict_qry[keyword] * df[keyword][df['doc'] == doc_num]\n",
    "        #||Query||\n",
    "        qry_mod += tfidf_dict_qry[keyword] * tfidf_dict_qry[keyword]\n",
    "        #||Document||\n",
    "        doc_mod += df[keyword][df['doc'] == doc_num] * df[keyword][df['doc'] == doc_num]\n",
    "    qry_mod = np.sqrt(qry_mod)\n",
    "    doc_mod = np.sqrt(doc_mod)\n",
    "    #implement formula\n",
    "    denominator = qry_mod * doc_mod\n",
    "    cos_sim = dot_product/denominator\n",
    "     \n",
    "    return cos_sim\n",
    "\n",
    "from collections import Iterable\n",
    "def flatten(lis):\n",
    "     for item in lis:\n",
    "        if isinstance(item, Iterable) and not isinstance(item, str):\n",
    "             for x in flatten(item):\n",
    "                yield x\n",
    "        else:        \n",
    "             yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "515623d5-7596-4da1-9644-f0fdd80231b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gold': 1.4054651081081644, 'silver': 2.09861228866811, 'truck': 1.4054651081081644}\n"
     ]
    }
   ],
   "source": [
    "def compute_query_idf(q):\n",
    "    idf_dict_qry = {}\n",
    "    sentence = q.split()\n",
    "    documents = [d1, d2, d3]\n",
    "    for word in sentence:\n",
    "        idf_dict_qry[word] = inverseDocumentFrequency(word ,documents)\n",
    "    return idf_dict_qry\n",
    "idf_dict_qry = compute_query_idf(q)\n",
    "print(idf_dict_qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "911f6473-09ad-4f26-929e-0aecee8159bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gold': 0.4684883693693881, 'silver': 0.6995374295560366, 'truck': 0.4684883693693881}\n"
     ]
    }
   ],
   "source": [
    "def compute_query_tfidf(q):\n",
    "    tfidf_dict_qry = {}\n",
    "    sentence = q.split()\n",
    "    for word in sentence:\n",
    "        tfidf_dict_qry[word] = query_norm_tf[word] * idf_dict_qry[word]\n",
    "    return tfidf_dict_qry\n",
    "tfidf_dict_qry = compute_query_tfidf(q)\n",
    "print(tfidf_dict_qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04a40d62-ec32-4360-88c5-f3d8366a7df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Document1', 'Document2', 'Document3']\n",
      "[0.4862404165915704, 0.842865485453629, 0.6876477917177425]\n"
     ]
    }
   ],
   "source": [
    "def rank_similarity_docs(data):\n",
    "    cos_sim =[]\n",
    "    for doc_num in range(0 , len(data)):\n",
    "        cos_sim.append(cosine_similarity(tfidf_dict_qry, df , q , doc_num).tolist())\n",
    "    return cos_sim\n",
    "similarity_docs = rank_similarity_docs(documents)\n",
    "doc_names = [\"Document1\", \"Document2\", \"Document3\"]\n",
    "print(doc_names)\n",
    "print(list(flatten(similarity_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9905ca82-8f4b-4f1e-a03c-6e1ad5584695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Document1', 'Document2', 'Document3']\n",
      "[0.4862404165915704, 0.842865485453629, 0.6876477917177425]\n"
     ]
    }
   ],
   "source": [
    "def rank_similarity_docs(data):\n",
    "    cos_sim =[]\n",
    "    for doc_num in range(0 , len(data)):\n",
    "        cos_sim.append(cosine_similarity(tfidf_dict_qry, df , q , doc_num).tolist())\n",
    "    return cos_sim\n",
    "similarity_docs = rank_similarity_docs(documents)\n",
    "doc_names = [\"Document1\", \"Document2\", \"Document3\"]\n",
    "print(doc_names)\n",
    "print(list(flatten(similarity_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e550ee-fd3a-4b23-8909-198e9af3f539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18982a8-ce64-49da-85b3-ed1b1df4d3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
